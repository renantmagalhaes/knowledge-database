# Delete all Evicted pods at once.
kubectl get pods -n default| grep Evicted | awk '{print $1}'  | xargs kubectl delete pod

# Delete all Terminating pods
kubectl get pods -n default| grep Terminating | awk '{print $1}'  | xargs kubectl delete pod --grace-period=0
kubectl get pods -n default| grep Terminating | awk '{print $1}'  | xargs kubectl delete pod --grace-period=0 --force

# Node selector
Kubectl get nodes
Kubectl label nodes $node_name hardware=$label_name

# Inside deployment
    spec:
      containers:
      - name: k8s-label
        image: dockerhub_image:latest
        ports:
        - name: docker_application
          containerPort: 3000
      nodeSelector:
        hardware: label_name

kubectl get nodes --show-labelskubectl get nodes --show-labels

# Health check
    spec:
      containers:
      - name: k8s-heath-check
        image: dockerhub_image:latest
        ports:
        - name: port_name #optional
          containerPort: 3000
        livenessProbe:
          httpGet:
            path: /
            port: port_name # or port number
          initialDelaySeconds: 15
          timeoutSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: port_name # or port number
          initialDelaySeconds: 15
          timeoutSeconds: 30

# Lifecyle
        lifecycle:
          postStart:
            exec:
              command: ['sh', '-c', 'echo $(date +%s): postStart >> /timing && sleep 10 && echo $(date +%s): end postStart >> /timing']
          preStop:
            exec:
              command: ['sh', '-c', 'echo $(date +%s): preStop >> /timing && sleep 10']


# Secrets 

## from file
echo -n "root" > ./username.txt
echo -n "password" > ./password.txt
kubectl create secret generic db-user-pass --from-file=./username.txt —from-file=./password.txt
secret "db-user-pass" created

## from ssh key or cert 
kubectl create secret generic ssl-certificate --from-file=ssh-privatekey=~/.ssh/id_rsa --ssl-cert-=ssl-cert=mysslcert.crt

## from yaml
echo -n "root" | base64
cm9vdA==
echo -n "password" | base64
cGFzc3dvcmQ=

apiVersion: v1
kind: Secret
metadata:
name: db-secret
type: Opaque
data:
password: cm9vdA==
username: cGFzc3dvcmQ=

kubectl create -f secrets-db-secret.yml

## Using secrets
env:
- name: SECRET_USERNAME
valueFrom:
secretKeyRef:
name: db-secret
key: username
- name: SECRET_PASSWORD

### OR 

volumeMounts:
- name: credvolume
mountPath: /etc/creds
readOnly: true
volumes:
- name: credvolume
secret:
secretName: db-secrets

The secrets will be stored in:
/etc/creds/db-secrets/username
/etc/creds/db-secrets/password

# DNS 
Inside the same pod, multiple containers can use localhost:port to communicate
Otherwise need to use the service type. 

## Communication between namespaces
app1-service.default
(service).(namespace name)
Or full path
app1-service.default.svc.cluster.local


# ConfigMap
Configuration parameters that are not secret, can be put in a ConfigMap
key and values pairs

cat <<EOF > app.properties
driver=jdbc
database=postgres
lookandfeel=1
otherparams=xyz
param.with.hierarchy=xyz
EOF

kubectl create configmap app-config —from-file=app.properties
Can use a a full configuration file, from nginx for example: kubectl create configmap app-config —from-file=nginx.config
Get a configmap value
kubectl get configmap
kubectl get configmap $configmap_name -o yaml


## Using configmap as volumeMounts
volumeMounts:
- name: config-volume
mountPath: /etc/config
volumes:
- name: config-volume
configMap:
name: app-config

## Using configmap as environment variables
env:
- name: DRIVER
valueFrom:
configMapKeyRef:
name: app-config
key: driver
- name: DATABASE
[...]

